{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "395fb9b5-8542-4285-8f96-260f7c0e43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# API Keys\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "FMP_API_KEY = os.getenv('FMP_API_KEY')\n",
    "FRED_API_KEY = os.getenv('FRED_API_KEY')\n",
    "NEWS_API_KEY = os.getenv('NEWS_API_KEY')\n",
    "ALPHA_VANTAGE_API_KEY = os.getenv('ALPHA_VANTAGE_API_KEY')\n",
    "# ----------------------------\n",
    "# Data Fetching Functions\n",
    "# ----------------------------\n",
    "def get_financial_data(ticker):\n",
    "    \"\"\"Fetch financial data from FMP API and rename volume to avoid conflict\"\"\"\n",
    "    url = f'https://financialmodelingprep.com/api/v3/quote/{ticker}?apikey={FMP_API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return {\n",
    "        'ticker': ticker,\n",
    "        'price': data[0]['price'],\n",
    "        'market_cap': data[0]['marketCap'],\n",
    "        'pe_ratio': data[0]['pe'],\n",
    "        'volume_financial': data[0]['volume'],  # Renamed to avoid conflict\n",
    "        'timestamp': datetime.now()\n",
    "    }\n",
    "\n",
    "def get_macro_data():\n",
    "    \"\"\"Fetch CPI and unemployment rate from FRED API\"\"\"\n",
    "    cpi_url = f'https://api.stlouisfed.org/fred/series/observations?series_id=CPIAUCSL&api_key={FRED_API_KEY}&file_type=json'\n",
    "    unemployment_url = f'https://api.stlouisfed.org/fred/series/observations?series_id=UNRATE&api_key={FRED_API_KEY}&file_type=json'\n",
    "    \n",
    "    cpi_data = requests.get(cpi_url).json()\n",
    "    unemployment_data = requests.get(unemployment_url).json()\n",
    "    \n",
    "    return {\n",
    "        'CPI': cpi_data['observations'][-1]['value'],\n",
    "        'unemployment_rate': unemployment_data['observations'][-1]['value']\n",
    "    }\n",
    "\n",
    "def get_stock_data(ticker):\n",
    "    \"\"\"Fetch stock data from Alpha Vantage (renamed volume to avoid conflict)\"\"\"\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={ticker}&apikey={ALPHA_VANTAGE_API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if 'Time Series (Daily)' in data:\n",
    "        latest_date = max(data['Time Series (Daily)'].keys())\n",
    "        latest_data = data['Time Series (Daily)'][latest_date]\n",
    "        return {\n",
    "            'ticker': ticker,\n",
    "            'date': latest_date,\n",
    "            'open': latest_data['1. open'],\n",
    "            'high': latest_data['2. high'],\n",
    "            'low': latest_data['3. low'],\n",
    "            'close': latest_data['4. close'],\n",
    "            'volume_stock': latest_data['5. volume'],  # Renamed\n",
    "            'timestamp': datetime.now()\n",
    "        }\n",
    "    return {}\n",
    "\n",
    "def get_sentiment(ticker):\n",
    "    \"\"\"Fetch news sentiment (placeholder - needs actual sentiment analysis)\"\"\"\n",
    "    url = f'https://newsapi.org/v2/everything?q={ticker}&apiKey={NEWS_API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    news_data = response.json()\n",
    "    return len(news_data.get('articles', []))  # Placeholder\n",
    "\n",
    "# ----------------------------\n",
    "# Data Processing Functions\n",
    "# ----------------------------\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Clean and prepare data for modeling\"\"\"\n",
    "    # Convert numeric columns\n",
    "    numeric_cols = [\n",
    "        'price', 'market_cap', 'pe_ratio', 'volume_financial',\n",
    "        'open', 'high', 'low', 'close', 'volume_stock',\n",
    "        'CPI', 'unemployment_rate', 'sentiment'\n",
    "    ]\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Fill missing values\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def predict_deal_success(df):\n",
    "    \"\"\"Run predictions (using dummy model)\"\"\"\n",
    "    # Exclude non-numeric columns before scaling\n",
    "    feature_columns = [\n",
    "        'price', 'market_cap', 'pe_ratio', 'volume_financial',\n",
    "        'open', 'high', 'low', 'close', 'volume_stock',\n",
    "        'CPI', 'unemployment_rate', 'sentiment'\n",
    "    ]\n",
    "    \n",
    "    # Filter only existing features\n",
    "    valid_features = [col for col in feature_columns if col in df.columns]\n",
    "    features = df[valid_features]\n",
    "    \n",
    "    # Dummy model setup\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(np.random.rand(10, len(valid_features)), np.random.randint(0, 2, 10))\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "    # Add predictions\n",
    "    df['prediction'] = model.predict(scaled_features)\n",
    "    return df\n",
    "\n",
    "# ----------------------------\n",
    "# Google Sheets Integration\n",
    "# ----------------------------\n",
    "def push_to_google_sheets(df):\n",
    "    \"\"\"Push results to Google Sheets\"\"\"\n",
    "    # Convert timestamps\n",
    "    df = df.applymap(lambda x: str(x) if isinstance(x, datetime) else x)\n",
    "    \n",
    "    # Auth and upload\n",
    "    scope = [\"https://spreadsheets.google.com/feeds\", \n",
    "             \"https://www.googleapis.com/auth/drive\"]\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name('manda-credentials.json', scope)\n",
    "    client = gspread.authorize(creds)\n",
    "    \n",
    "    sheet = client.open_by_key('1ym4CpD5J6OCy_TnC8DEp4fN73yn5hSP7sKQ16_RQEdg')\n",
    "    worksheet = sheet.get_worksheet(0)\n",
    "    worksheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
    "\n",
    "# ----------------------------\n",
    "# Main Workflow\n",
    "# ----------------------------\n",
    "def main(tickers):\n",
    "    # Fetch and merge data\n",
    "    all_data = []\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            data = {\n",
    "                **get_financial_data(ticker),\n",
    "                **get_stock_data(ticker),\n",
    "                **get_macro_data(),\n",
    "                'sentiment': get_sentiment(ticker)\n",
    "            }\n",
    "            all_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch data for {ticker}: {str(e)}\")\n",
    "    \n",
    "    # Process and predict\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df = preprocess_data(df)\n",
    "    df = predict_deal_success(df)\n",
    "    \n",
    "    # Push results\n",
    "    push_to_google_sheets(df)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(['AAPL', 'GOOG', 'AMZN', 'MSFT', 'TSLA'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
